# 介绍一下FDBus

- 分布式：基于TCP socket和Unix Domain socket（UDS），既可用于本地IPC，也支持网络主机之间的IPC
- 跨平台：目前已在Windows，Linux和QNX上验证
- 高性能：点对点直接通信，不通过中央Hub或Broker转发
- 安全性：能够为server的方法调用也事件**广播配置不同等级的访问权限，只有权限足够高的client才能特点方法和接收特定事件**
- 服务名解析：server地址用名字标识，**通过name server注册服务和解析名字**，从而server可以在全网络任意部署
- 支持跨平台的中间件开发框架，包括如下**组件**：
  - Thread模型
  - Event Loop
  - 基于Job-Worker的线程间通信
  - 基于Event Loop的Timer
  - 基于Event Loop的watch
  - Mutex
  - Semaphore
  - Socket
  - Notification
- IPC采用Client-Server模式，支持如下通信模式：
  - 带超时的**同步请求-答复**
  - 带超时的**异步请求-答复**
  - **无答复的命令请求**
  - **注册-发布**模式，实现**多点广播**

- IPC消息采用Protocol buffer**序列化和反序列化**，支持IDL代码生成，高效简便；也支持raw data格式，便于大量数据传输
- 可靠的**心跳和重连机制**，确保无论网络状况如何，无论哪个服务重新上线或重启，通信各方都能保持连接
- C++实现，**易于开发和维护**

![image-20240423173623681](D:\A_Document\Routine_Document\实习\学习\image-20240423173623681.png)

## 基于FDBus的中间件模型

![img](D:\A_Document\Routine_Document\实习\学习\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2plcmVteV9jeg==,size_16,color_FFFFFF,t_70.png)



- 多线程协同工作要求线程之间能够传递消息和数据，例如文件下载完毕要通知endpoint做后续处理。在进程内由于可以访问同一地址空间，**最好的通信载体是对象 - 既能承载数据，还能指定数据的处理方式**。**job就是FDBus在线程之间传递的对**象，通过job在线程之间的传递和执行实现进程间通信。
  
- FDBus更重要的功能是进程间通信（IPC）。进程之间无法直接传递对象，只能**以消息形式交互**，并且消息传**输过程中需要做序列化，接收到消息后需要做反序列化**。

## 既然socket能进行进程间通信，为何还要封装为FDBUS

- 不同于一般意义上的socket server，**FDBus server可以同时绑定多个地址**，**每个地址都可接受client的连接**。一旦连接上，每个地址都提供同样的服务，所以client可以选择任意一个地址建立连接。下面是一个FDBus server地址绑定示意图

  ![img](D:\A_Document\Routine_Document\实习\学习\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2plcmVteV9jeg==,size_16,color_FFFFFF,t_70-1713866209024-3.png)

  - 上图中，server绑定了一个UDS地址：file:///tmp/fdb-ipc1。同一主机上的client可以用该地址发起连接，当然也可连接到其它任意地址，但无疑使用UDS是最高效的，且UDS支持peer credentials，进而支持安全策略。由于主机有多个网口，server还可以在每个网口上各绑定一个地址（端口号）：tcp://192.168.1.2:60004和tcp://192.168.0.1:60004。每个地址用于连接对应网段的client。

- 心跳检测，重连和上线、离线检测:
  - 为了使整个系统可靠运行，保证任何服务都可以优雅重启（重启后整个系统依旧正常工作），FDBus有完善的心跳检测和上线、离线检测机制：

- 安全性 (Security)
  - 主机节点的鉴权：所有加入**FDBus的主机都划分成不同的安全等级**
  - 服务访问的鉴权：所有**client都划分成不同的安全等级**
  - 访问限制：将**server的方法调用和事件广播划分安全等级**，**client才能调用与server安全等级相匹配的的方法和注册相匹配的事件广播**
    

FDBUS 是一种基于 Unix 域套接字的进程间通信机制,它在 socket 的基础上进行了进一步封装和抽象,提供更高级的接口和功能。以下是 FDBUS 相比直接使用 socket 的一些优势:

1. **更高级的接口**: FDBUS 提供了更加友好和易用的编程接口,隐藏了底层 socket 的复杂性,使得开发人员可以更加专注于业务逻辑的实现。

2. **更高效的通信**: FDBUS 采用了一些优化措施,如`批量传输`、`异步 I/O 等`,可以提`高通信的效率`和性能。

3. **更健壮的错误处理**: FDBUS 提供了更加完善的`错误处理机制`,可以更好地应对各种异常情况。

4. **更丰富的功能**: FDBUS 除了基本的`进程间通信`,还提供了`消息订阅/发布`、远程过程调用等更高级的功能,满足更复杂的应用需求。

5. **更好的可维护性**: FDBUS 的抽象层次更高,代码结构更清晰,有利于项目的可维护性和可扩展性。

总的来说,FDBUS 是在 socket 的基础上进行了`进一步的封装和抽象`,提供了更加丰富和易用的编程接口,从而更好地满足了现代软件开发的需求。



# 介绍一下socket通信原理和流程

Socket 通信是基于客户端-服务器模型的一种常见的网络通信方式。它的工作原理和流程如下:

1. **套接字的创建**:
   - 服务器端创建一个 Socket 套接字,指定通信协议(如 TCP 或 UDP)和监听端口号。
   - 客户端也创建一个 Socket 套接字,准备发起连接请求。

2. **连接建立**:
   - 服务器端调用 `listen()` 函数开始监听指定端口。
   - 客户端调用 `connect()` 函数向服务器发起连接请求。
   - 如果连接成功建立,服务器端会通过 `accept()` 函数接受客户端的连接请求。

3. **数据传输**:
   - 连接建立后,双方可以通过 `send()` 和 `recv()` 函数进行数据的发送和接收。
   - 数据在网络上以数据包的形式进行传输,遵循 TCP/IP 协议栈。

4. **连接关闭**:
   - 通信结束后,任意一方都可以调用 `close()` 函数来关闭连接。
   - 如果是 TCP 连接,在关闭时会经历 "四次挥手" 的过程。

Socket 通信的主要特点包括:

- 基于客户端-服务器模型,支持多客户端同时连接。
- 可以在不同主机上的进程之间进行通信。
- 支持 TCP 和 UDP 两种主要的网络协议。
- 提供了丰富的编程接口,方便开发人员使用。
- 可以跨语言进行通信,如 C/C++、Java、Python 等。

Socket 通信广泛应用于各种网络应用程序的开发,如 Web 服务器、聊天应用、文件传输等。它是网络编程的基础,理解其工作原理和流程对于网络编程非常重要。



# 介绍一下IIC

![image-20240421154401889](D:\A_Document\Routine_Document\实习\学习\image-20240421154401889.png)

#### I2C（串、同步、半双工）

![image-20240331172136213](D:\A_Document\Routine_Document\实习\学习\image-20240331172136213.png)

- IIC总线是一种多主机总线，连接在IIC总线上的器件分为主机和从机
- 主机有权发起和结束一次通信，`而从机只能被主机呼叫;`
- 当总线上有多个主机同时启用总线时，IIC也**具备冲突检测和仲裁的功能**来防止错误产生
- 每个连接到IIC总线上的器件都有**一个唯一的地址(7bit)，**
- 且每个器件都可以**作为主机也可以作为从机(同一时刻只能有一个主机**).
- 总线上的器件增加和删除不影响其他器件正常工作;
- IIC总线在通信时总线上发送数据的器件为发送器，接收数据的器件为接收器;

![image-20240331193919468](D:\A_Document\Routine_Document\实习\学习\image-20240331193919468.png)

#### IIC总线通信过程

1. 主机发送起始信号启用总线

2. 主机发送一个字节数据指明从机地址和后续字节的传送方向

3. 被寻址的从机发送应答信号回应主机

4. 发送器发送一个字节数据

5. 接收器发送应答信号回应发送器

6. (循环步骤4、5)

7. 通信完成后主机发送停止信号释放总线

   

   ![image-20240331193744169](D:\A_Document\Routine_Document\实习\学习\image-20240331193744169.png)
   
   

# 介绍一下RS485

![image-20240421154401889](D:\A_Document\Routine_Document\实习\学习\image-20240421154401889.png)

基于UART（串口）:串、异步、两根线；但两根线做差分，所以半双工。

![image-20240331170535577](D:\A_Document\Routine_Document\实习\学习\image-20240331170535577.png)

![image-20240331170830952](D:\A_Document\Routine_Document\实习\学习\image-20240331170830952.png)

![image-20240331170853961](D:\A_Document\Routine_Document\实习\学习\image-20240331170853961.png)

![image-20240331171211084](D:\A_Document\Routine_Document\实习\学习\image-20240331171211084.png)

# 介绍一下高通音频架构

1. **Qualcomm Aqstic音频编解码器**:
   - 高通Aqstic是一系列高性能的音频编解码器,支持多种音频编码格式如PCM、MP3、AAC等。
   - 提供低功耗、低噪音、高动态范围等特性,广泛应用于智能手机、平板电脑等移动设备。

2. **Qualcomm Hexagon DSP**:
   - Hexagon是高通自主研发的数字信号处理器(DSP),专门用于音频、视频、图像等多媒体处理。
   - 与主处理器CPU协同工作,可以卸载音频编解码、音效处理等任务,提高整体性能。

3. **Qualcomm audio HAL**:
   - HAL(Hardware Abstraction Layer)是高通提供的音频硬件抽象层,屏蔽了底层音频硬件的复杂性。
   - 为上层应用程序提供统一的音频编程接口,方便开发者使用。

4. **Qualcomm audio effects**:
   - 高通提供了一系列音频效果处理模块,如环绕声、均衡器、重低音增强等。
   - 这些音频效果可以在Hexagon DSP上进行硬件加速处理,提高性能。

5. **Qualcomm audio frameworks**:
   - 高通在Android、Windows等主流操作系统上提供了音频框架支持,如ALSA、DirectSound等。
   - 这些框架集成了Aqstic编解码器、Hexagon DSP以及audio HAL等组件,为上层应用提供完整的音频解决方案。

总的来说,高通的音频架构是一个集成了硬件编解码器、DSP加速、软件框架的完整音频解决方案,广泛应用于各类移动设备和消费电子产品中。



## 介绍一下PCM

PCM (Pulse Code Modulation) 是一种常见的数字音频编码方式,它通过采样和量化的方式将模拟音频信号转换为数字信号。以下是 PCM 的主要特点:

1. **采样**:
   - PCM 将连续的模拟音频信号按一定频率进行采样,得到一系列离散的采样点。
   - 采样频率决定了音频的频带宽度,通常为 44.1 kHz 或 48 kHz。

2. **量化**:
   - 每个采样点的幅度值被量化成有限个离散的数字值,通常为 16 位或 24 位。
   - 量化过程会引入量化噪声,但可通过增加量化位数来降低噪声。

3. **编码**:
   - 量化后的数字值被编码成二进制序列,这就是 PCM 编码的结果。
   - PCM 编码通常采用线性编码,即每个样本点都被独立编码。

4. **特点**:
   - PCM 是一种简单、高效的数字音频编码方式,实现相对容易。
   - 由于采样和量化的引入,PCM 编码会引入一定的失真和噪声,但可通过提高采样率和量化位数来改善。
   - PCM 编码广泛应用于 CD、DVD、HDTV 等领域,是数字音频的基础编码方式。

总的来说,PCM 是一种基于采样和量化的数字音频编码技术,在音频领域有着广泛的应用和重要地位。理解 PCM 的工作原理和特点对于数字音频的学习和应用很有帮助。



## 介绍一下ALSA

ALSA (Advanced Linux Sound Architecture) 是 Linux 操作系统下的一种音频框架,它提供了一套完整的音频处理和管理机制。以下是 ALSA 的主要特点:

1. **硬件抽象**:
   - ALSA 提供了一个统一的音频硬件抽象层,屏蔽了底层音频设备的复杂性。
   - 上层应用程序可以通过标准的 ALSA API 访问和控制音频硬件。

2. **设备管理**:
   - ALSA 负责管理系统中的各种音频设备,如声卡、麦克风、扬声器等。
   - 应用程序可以通过 ALSA 查询、打开、配置和使用这些音频设备。

3. **多媒体支持**:
   - ALSA 支持多种音频格式,如 PCM、MIDI、AC3 等,可以处理各种类型的多媒体数据。
   - 提供了丰富的音频处理功能,如混音、均衡、音效等。

4. **低延迟**:
   - ALSA 采用了多种优化技术,如 JACK 和 Firewire 等,可以实现低延迟的音频传输。
   - 这使得 ALSA 非常适合于实时音频应用,如音乐制作、视频编辑等。

5. **可扩展性**:
   - ALSA 具有良好的可扩展性,支持动态加载音频驱动模块。
   - 用户可以根据需求添加新的音频设备支持。

6. **跨平台**:
   - ALSA 最初是为 Linux 操作系统开发的,但也有在 Windows 和 macOS 上的移植版本。

总的来说,ALSA 是 Linux 音频系统的核心组件,为上层应用程序提供了一个统一、高效的音频处理接口。它的出现极大地促进了 Linux 在多媒体领域的发展。ALSA 广泛应用于桌面、嵌入式和服务器等各类 Linux 系统中。



# 析构函数里虚函数修饰的初衷

总的来说虚析构函数是为了避免内存泄露，而且是当子类中会有指针成员变量时才会使用得到的。也就说**虚析构函数使得在删除指向子类对象的基类指针时可以调用子类的析构函数达到释放子类中堆内存的目的，而防止内存泄露的**.

# 智能指针多线程下安全问题

[深入理解C++智能指针：分类、使用及多线程安全性_c++ 智能指针 线程安全-CSDN博客](https://blog.csdn.net/u010349629/article/details/130569773)

![image-20240417193136177](D:\A_Document\Routine_Document\实习\学习\image-20240417193136177.png)

# can总线的帧结构

[图解CAN总线数据的组成和帧格式_can总线帧头-CSDN博客](https://blog.csdn.net/LEON1741/article/details/106199472)

![image-20240417194438849](D:\A_Document\Routine_Document\实习\学习\image-20240417194438849.png)

# HTTP和HTTPS。

常见的 HTTP 请求方式有四种：

- `POST`（添加）

- `GET`（查询）

- `DELETE`（删除）

- `PUT`（修改）

  [详解HTTP四种请求：POST、GET、DELETE、PUT - 掘金 (juejin.cn)](https://juejin.cn/post/7239586416883122235)

HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式：

- 1、TCP 三次同步握手
- 2、客户端验证服务器数字证书
- 3、DH 算法协商对称加密算法的密钥、hash 算法的密钥
- 4、SSL 安全加密隧道协商完成
- 5、网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。

区别：

- HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。
- http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。
- HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源

# 对称加密和非对称加密

[数学不好也能听懂的算法 - RSA加密和解密原理和过程_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1XP4y1A7Ui/?spm_id_from=333.337.top_right_bar_window_history.content.click)

![image-20240418204511168](D:\A_Document\Routine_Document\实习\学习\image-20240418204511168.png)

![image-20240418204539831](D:\A_Document\Routine_Document\实习\学习\image-20240418204539831.png)

# 线程如何同步

请说一下线程间同步方式有哪些

> 同一进程内的多个线程共享同一地址空间
> 为了避免多个线程同时访问数据造成的混乱
> 需要考虑线程之间的同步问题
> 所谓同步及协同步调
> 按预定的先后次序访问共享资源
> 以免造成混乱

线程同步的实现方式主要有六种

> 互斥锁
> 自旋锁
> 读写锁
> 条件变量
> 屏障信号量一互斥锁

#### 互斥锁

在访问共享资源前对互斥量进行加锁
在访问完成后释放互斥量进行解锁
对护士量加锁以后
任何其他视图再次被护士量加锁的
线程都会被堵塞
直至当前线程释放该户质量

#### 二自旋锁

自旋锁与互斥量类似

> 但它不使线程进入阻塞态

而是在获取锁之前一直占用CP
处于盲等自旋状态
自旋锁适用于所谓持有的时间短
且线程不希望在重新调度上
花费太多成本的情况

#### 三读写锁

读写锁有三种状态图模式加锁
写模式
加锁和不加锁
因此只有一个线程可以占有写模式的读写锁
但是多个线程可以同时占有毒模式的读写锁
读写锁非常适合
对数据结构图的次数远大于写的情况

![image-20240417204518986](D:\A_Document\Routine_Document\实习\学习\image-20240417204518986.png)

#### 四条件变量

条件变量允许线程睡眠
直到满足某种条件
当满足条件时
可以向该线程发送信号通知
并唤醒该线程
条件变量通常与互斥量配合一起使用
条件变量由互斥量保护
县城在改变条件状态之前
必须首先锁住护士量
其他县城在获得护食量之前
不会察觉到条件的改变
因为必须在锁住互斥量之后
它才可以计算条件是否发生变化

#### 五屏障

屏障是用户协调多个线程并行工作的同步机制
屏障允许每个线程等待
直到所有的合作线程都到达某一点
然后从该点继续执行

![image-20240417204849363](D:\A_Document\Routine_Document\实习\学习\image-20240417204849363.png)

#### 六信号量

信号量本质上是一个计数器
用于为多个进程提供共享数据对象的访问
编程时可根据操作信号量值的结果
判断是否对公共资源具有访问的权限
当信号量值大于零时
则可以访问
否则将左侧霹雳元宇是对信号量的操作
一次P操作使信号量减一
一次B操作使信号量加一
编程10万位
每天一问
关注我
每天学习一个编程小知识

[多线程同步的四种方式（史上最详细+用例） - Chilk - 博客园 (cnblogs.com)](https://www.cnblogs.com/Chlik/p/13556720.html)

# 多态原理

多态分为静态多态和动态多态，静态多态有函数重载、模板等实现方式，而动态多态则有虚函数方式和variant实现。这种基于动态绑定（dynamic binding）和运行时多态性（runtime polymorphism）实现的多态性可以使得程序更加灵活、可扩展和易于维护。

C++中的多态是通过虚函数（virtual function）实现的。当一个类中的成员函数被声明为虚函数时，编译器会自动生成一个虚表（virtual table），其中存储了该类所有虚函数的地址。当创建一个对象时，编译器会在对象内部添加一个指向该类虚表的指针。当调用一个虚函数时，实际上是通过该对象内部存储的虚表指针找到对应的虚表，并根据函数在虚表中的位置找到相应的地址进行调用。
当子类重写父类中的某个虚函数时，子类会生成自己独有的虚表，并将重写后的函数地址存入其中。当通过父类指针或引用调用该虚函数时，由于对象内部存储了指向子类自己独有的虚表指针，因此会调用子类重写后的版本。

# 地址空间分布

**程序段(Text):**程序代码在内存中的映射，存放函数体的二进制代码。

**初始化过的数据(Data):**在程序运行初已经对变量进行初始化的数据。

**未初始化过的数据(BSS):**在程序运行初未对变量进行初始化的数据。

**栈 (Stack):**存储局部、临时变量，函数调用时，存储函数的返回指针，用于控制函数的调用和返回。在程序块开始时自动分配内存,结束时自动释放内存，其操作方式类似于数据结构中的栈。

**堆 (Heap):**存储动态内存分配,需要程序员手工分配,手工释放.注意它与数据结构中的堆是两回事，分配方式类似于链表。

# 迪杰斯特拉算法

迪杰斯特拉（Dijkstra）算法是一种典型的最短路径算法，用于计算一个节点到其他节点的最短路径。它的主要特点是以起始点为中心，按照路径长度递增的次序扩展，直到扩展到终点为止。让我来详细解释一下迪杰斯特拉算法的基本思想和步骤：



# 乱序字符串的题目

```C++
#include <iostream>
#include <vector>
#include <unordered_map>
#include <algorithm>

std::vector<std::string> findAnagrams(std::vector<std::string>& strs) {
    std::unordered_map<std::string, std::vector<std::string>> map;
    for (auto& str : strs) {
        std::string key = str;
        // 对字符串进行排序作为键
        std::sort(key.begin(), key.end());
        // 将原字符串添加到对应键的vector中
        map[key].push_back(str);
    }

    std::vector<std::string> result;
    // 遍历map，将所有包含多个字符串的vector加入结果中
    for (auto& pair : map) {
        if (pair.second.size() > 1) { // 确保是乱序字符串
            result.insert(result.end(), pair.second.begin(), pair.second.end());
        }
    }

    return result;
}

int main() {
    std::vector<std::string> strs = {"lint", "intl", "inlt", "code"};
    auto anagrams = findAnagrams(strs);

    for (auto& str : anagrams) {
        std::cout << str << " ";
    }
    std::cout << std::endl;

    return 0;
}
```

# 虚函数表结构

`虚表是一个指针数组`，其元素是`虚函数的指针`，每个元素对应一个虚函数的函数指针。需要指出的是，普通的函数即非虚函数，其调用并不需要经过虚表，所以`虚表的元素并不包括普通函数的函数指针。`
虚表内的条目，即`虚函数指针的赋值发生在编译器的编译阶段`，也就是说在代码的编译阶段，虚表就可以构造出来了。

![img](D:\A_Document\Routine_Document\实习\学习\v2-e864f4fe6a480b3230a5c9aebd7df996_720w.webp)

# 三次握手四次挥手

**进行三次握手的目的是为了确认双方的接收能力和发送能力是否正常。**

- 第一次握手： TCP客户进程也是先创建`传输控制块TCB`，然后向服务器发出`连接请求报文`

- 第二次握手 ：TCP服务器收到请求报文后，如果同意连接，则会向客户端发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1。

- 第三次握手 ：TCP客户端收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立。
  

![图片来自网络，侵权请告知，会及时删除](D:\A_Document\Routine_Document\实习\学习\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ltcGFjdF9mYWN0b3I=,size_16,color_FFFFFF,t_70.png)



# 进程结构

操作系统中,进程是资源分配的基本单位。每个进程都有自己的进程结构,用于描述和管理进程的各种信息。进程结构的主要组成部分如下:

1. `进程标识符(PID)`:唯一标识一个进程的数字。

2. `进程状态`:进程当前所处的状态,如`就绪、运行、阻塞`等。

3. `程序计数器`:指向`下一条要执行的指令地址`。

4. `寄存器组`:保存进程执行所需的各种`数据和地址`。

5. `内存空间`:进程所需的`代码、数据和栈等内存区域`。

6. `打开文件列表`:进程打开的所有文件。

7. `用户ID和组ID`:进程所属的用户和组。

8. `环境变量`:进程运行所需的环境变量。

9. `优先级`:进程被调度的优先级。

10. `进程控制块(PCB)`:进程的全部信息都记录在PCB中,是操作系统管理进程的核心数据结构。

进程结构的设计目的是为了操作系统能够有效地管理和调度进程,确保各个进程可以独立、安全地运行。不同操作系统的进程结构可能会有一些差异,但上述组成部分是通用的。



# 虚拟地址和物理地址间转换

`虚拟地址和物理地址之间的转换需要通过内存管理单元(MMU)来完成`,具体过程如下:

1. 虚拟地址转换:
   - 当进程访问某个虚拟地址时,CPU会将这个虚拟地址送入MMU进行转换。
   - MMU会查询`页表`(Page Table)或`段表`(Segment Table),找到对应的`物理页框`(Page Frame)地址。
   - 页表或段表中存储了虚拟地址到物理地址的映射关系。

2. 物理地址访问:
   - 得到物理页框地址后,MMU会将虚拟地址的`页内偏移量`加上`物理页框地址`,形成最终的物理地址。
   - CPU然后使用这个物理地址访问实际的物理内存。

3. 地址转换过程:
   - 虚拟地址 -> `页表/段表`查找 -> `物理页框`地址 -> `物理地址`

这种虚拟地址到物理地址的转换机制,使得`每个进程都拥有独立`的地址空间,`互不干扰`。同时也为操作系统提供了灵活的内存管理方式,如`分页、分段`等。

需要注意的是,如果访问的虚拟地址`没有对应的物理页框`,就会发生`缺页中断`,操作系统需要进行`页面置换`等操作来完成地址转换。

# 分页、分段区别

页表和段表都是用于实现虚拟地址到物理地址转换的关键数据结构,但它们在实现方式和特点上有所不同:

1. 页表(Page Table):
   - 页表采用分页机制,将`虚拟地址空间划分为固定大小的页`(通常为`4KB`)。
   - 页表中的每一项记录了一个虚拟页到物理页框的映射关系。
   - 页表结构通常采用多级页表,以提高转换效率和支持大容量虚拟地址空间。
   - 页表方式灵活性强,可以方便地实现内存分页管理和页面置换。
   - 页表结构复杂,查找时间较长,需要`额外的硬件支持(如TLB)`来提高转换速度。

2. 段表(Segment Table):
   - 段表采用分段机制,将虚拟地址空间划分为可变长度的段。
   - 段表中的每一项记录了一个虚拟段的起始地址和长度,以及对应的物理内存位置。
   - `段表结构相对简单,查找速度较快`,不需要额外的硬件支持。
   - `段表方式灵活性较弱``,不利于内存管理和页面置换`,但对于某些应用场景(如代码段和数据段分离)比较适用。
   - 段表机制通常与页表机制结合使用`,形成分段分页的混合寻址方式。`

# 混合寻址方式

混合寻址是指同时使用分段和分页机制进行虚拟地址到物理地址的转换。它结合了段表和页表两种方式的优点,是现代操作系统中常用的地址转换方式。具体步骤如下:

1. 段地址转换:
   - 首先将`虚拟地址拆分为段号和段内偏移量`。
   - 通过`段表查找得到对应段的起始物理地址`。

2. 页地址转换:
   - 将`段内偏移量`进一步拆分为`页号和页内偏移量`。
   - 通过页表查找得到对应页框的物理地址。

3. 物理地址计算:
   - 将`段起始物理地址`与`页框物理地址`相加,得到最终的`物理地址`。
   - `页内偏移量作为物理地址的低位字节`。

整个转换过程可以用公式表示为:

```
物理地址 = 段起始物理地址 + 页框物理地址 + 页内偏移量
```

这种混合寻址方式结合了分段和分页的优点:

- 分段可以提供更大的地址空间和更好的内存保护。
- 分页可以实现更灵活的内存管理和页面置换。
- 两者结合可以充分利用硬件资源,提高地址转换的效率。

混合寻址方式广泛应用于x86等计算机体系结构中,是现代操作系统中主要的虚拟地址到物理地址转换机制。



# malloc后直接分配内存吗？返回后指向什么

当我们调用 `malloc()` 函数来动态分配内存时,它的行为并不是直接分配内存并返回指向已分配内存的指针。实际上,`malloc()` 函数的工作流程如下:

1. 检查请求分配的内存大小:
   - `malloc()` 首先会检查请求分配的内存大小是否合法,即是否超出系统支持的最大值。

2. 在堆中查找可用空间:
   - `malloc()` 会在进程的堆中搜索足够大的可用空间来满足请求。
   - 堆是操作系统为进程分配的一块动态内存区域,用于存储动态分配的内存块。

3. 分配内存并返回指针:
   - 如果找到了足够大的可用空间,`malloc()` 会从中分配出一块内存,并返回一个指向该内存块起始位置的指针。
   - 这个指针就是 `malloc()` 函数的返回值,指向了刚刚分配的内存块。

需要注意的是,刚刚分配的内存块的内容是未初始化的,也就是说其中的数据是随机的。如果需要初始化内存,可以使用 `calloc()` 函数,它会将分配的内存块全部初始化为0。

总之,`malloc()` 函数并不是直接分配内存,而是在堆中查找可用空间,然后返回一个指向该内存块的指针。这个指针就是应用程序可以使用的动态分配内存。

# 返回值是什么？返回什么类型指针

malloc 向系统申请分配指定size个字节的内存空间。返类型是 void* 类型。void* 表示未确定类型的指针。C,C++规定，答void* 类型可以强制转换为任何其它类型的指针。
原型：
　　extern void *malloc(unsigned int num_bytes);
头文件：
#include <stdlib.h>
功能：
　　分配长度为num_bytes字节的内存块
　　…malloc（n）
　　就分配n个字节大小的空间
返回值：
　　**

如果`分配成功`则返回指向`被分配内存的指针`(此存储区中的初始值不确定)，`否则返回空指针NULL`
。**当内存不再使用时，应使用free()函数将内存块释放。
**

所以在使用时最好给malloc做一个强制类型转化， 例如：p=（stu*）malloc(sizeof(stu))
**

# 一个局域网访问淘宝的过程，怎么回包给局域网

- 第一步：确定本机参数

​      (本机ip，本机端口号，使用的网络协议，要访问的机器的ip，要访问机器的端口号)

- 第二步：确定我们要访问的内容，此处我们还是以访问百度为例，假设我们输入www.baidu.com,然后回车（其实更加具体的写法应该是http://www.baidu.com:8080/index.php,这里不过是浏览器帮我们补齐了而已）。

- 第三步：我们此时要确定的是百度的ip地址，此时就轮到我们的DNS服务器出马了，大致的解析过程可以参看前文，这里从数据包的角度进行分析：

![img](D:\A_Document\Routine_Document\实习\学习\Center.png)

DNS服务器告诉我们百度的ip地址是：115.239.211.112

- 第四步：利用子网掩码判断我们访问的ip是否和我们是同一个网段(判断方法上面已经给出了)，经过判断，我们要访问的ip跟我们不是同一个网段，因此，我们向百度发送数据包必须通过网关转发。也就是说接收方的mac地址是网关的mac地址（如果是同一个网段的话mac地址就是我们要访问的机器的mac地址）。【先ping网关，再用arp -a就可以得到网关mac地址】

第五步：应用层

![img](D:\A_Document\Routine_Document\实习\学习\SouthEast.png)

http请求的内容如下：假定其长度为4960个字节，他会被嵌在tcp数据包之中。

- 第六步：传输层（TCP协议）

    Tcp数据包需要设置端口，接收方的默认端口是80，本机的端口是一个随机生成的1024到65535之间的整数。假定为8888。
Tcp数据包的包头长度为20字节，加上http数据包，为4980字节。

- 第七步：网络层（IP协议）

然后tcp数据包再嵌入ip数据包，ip数据包需设置双方ip【已知】。Ip数据包的头长度为20字节，总共是5000字节

- 第八步：网际接口层（以太网协议）

Ip数据包嵌入以太网数据包，以太网数据包需设置双方mac地址【已知】，接收方即网关mac地址【通过arp协议得到】。以太网数据包的数据部分最大为1500字节，因此ip数据包必须分成4个包，因为每个包都有自己的ip标头，因此四个包的ip数据包的长度分

![img](D:\A_Document\Routine_Document\实习\学习\SouthEast-1713444748923-11.png)



- 第九步：服务器响应

经过多个网关转发，具体的路由协议，可以参考计算机网络一书，百度服务器收到这四个以太网数据包，根据ip标头的序号，将四个包拼起来，取出完整的tcp数据包，读出”http请求”，做出“http响应”。再使用http协议发回来。完成通信。



# 内存对齐作用

内存对齐是一种计算机体系结构中的一种重要概念,它对于程序的性能和正确性都有重要影响。内存对齐的主要作用包括:

1. 提高访问效率:
   - `大多数处理器都要求数据必须按照特定的边界对齐,才能进行高效的内存访问`。
   - 如果数据没有对齐,处理器可能需要进行多次内存访问,降低访问效率。

2. 减少内存访问异常:
   - `某些处理器在访问未对齐的数据时会产生异常,导致程序崩溃。`
   - 对数据进行对齐可以避免这种异常情况的发生,提高程序的稳定性。

3. 节省存储空间:
   - 为了满足对齐要求,编译器可能会在结构体或类中插入填充字节。
   - 合理的内存对齐可以减少这种填充字节的浪费,节省存储空间。

4. `提高并行处理性能:`
   - 对齐的数据可以更好地利用处理器的向量指令,提高并行处理的性能。
   - 向量指令通常要求数据在内存中是对齐的,才能高效执行。

内存对齐的具体规则因处理器架构而有所不同,但通常遵循以下原则:

- `基本数据类型(如 int, float)应该按照自身大小对齐`。
- `结构体/类的成员变量`应该按照`最大成员变`量的大小进行对齐。
- `数组元素`应该按照`数组元素类型`的大小对齐。

合理的内存对齐可以显著提高程序的性能和稳定性,是编程中需要重点关注的一个方面。

# static作用、在.h文件中加static作用

`static` 关键字在 C/C++ 中有多种用法,主要作用包括:

1. static修饰`局部变量`时:
   - 对其存储位置进行改变，`存储在静态区`；改变其生命周期，为`整个源程序`，因此它只被初始化一次，并且被声明为静态的变量在这一函数被调用过程中维持其值不变。
2. static修饰`全局变量`时: 
   - 改变其作用域，在`模块内 (`但在函数体外)，一个被声明为静态的变量可以被模块内所用函数访问，但不能被模块外其它函数访问，它是一个本地的全局变量 (只能被当前文件使用)
3. static修饰函数时:
   - 改变其作用域，一个被声明为静态的函数只可被这一模块内的其它函数调用。即，这个函数被限制在声明它的模块的本地范围内使用 (只能被当前文件使用)

4. `修饰文件`作用域:
   - 文件作用域 `static`: 在文件开头使用 `static` 修饰,表示该文件内所有全局变量和函数都是静态的,仅在该文件内可见。

现在重点讨论在 `.h` 头文件中使用 `static` 的作用:

1. 静态函数:
   - 在头文件中声明 `static` 函数,可以限制该函数的可见性仅在当前源文件内。
   - 这样可以`避免在多个源文件中定义同名函数`,提高代码的模块化和可维护性。

2. 静态全局变量:
   - 在头文件中声明 `static` 全局变量,可以限制该变量的可见性仅在当前源文件内。
   - 这样可以避免在多个源文件中定义同名全局变量,`减少命名冲突`。

总的来说,在头文件中使用 `static` 可以达到以下目的:

1. `隐藏实现细节,提高代码的封装性。`
2. `避免命名冲突`,提高代码的可维护性。
3. `减少编译时的符号泄露`,提高编译效率。

# docker作用

Docker 是一种容器化技术,它的主要作用包括:

1. 应用程序打包和部署:
   - Docker 可以将应用程序及其依赖项打包成标准化的容器镜像。
   - 这些容器�像可以在任何支持 Docker 的环境中快速部署和运行,大大简化了应用程序的交付过程。

2. 环境隔离和一致性:
   - Docker 容器`提供了一个独立的运行环境`,与宿主机操作系统和其他容器隔离。
   - 这确保了应用程序在不同环境(如开发、测试、生产)中的运行一致性。

3. 资源利用效率:
   - Docker 容器`比虚拟机更轻量,启动和停止更快`,资源利用率更高。
   - 这使得 Docker 非常适合于微服务架构和弹性伸缩的场景。

4. 持续集成和部署:
   - Docker 配合 CI/CD 工具可以实现应用程序的自动化构建、测试和部署。
   - 这大大提高了软件交付的效率和可靠性。

5. 跨平台迁移:
   - Docker 容器`可以在不同操作系统和硬件平台上运行,降低了应用程序的迁移成本`。

6. 简化开发和运维:
   - Docker 提供了一致的开发、测试和生产环境,减少了环境差异带来的问题。
   - 运维人员可以更容易地管理和编排 Docker 容器化的应用程序。

总的来说,Docker 通过容器化技术,解决了`应用程序交付`、`环境一致性`、资源利用效率等方面的问题,极大地提高了软件开发和运维的效率。它已经成为当前云原生应用架构中不可或缺的一部分。

# TCP和UDP的区别？

TCP(Transmission Control Protocol)和UDP(User Datagram Protocol)是两种不同的网络传输协议,它们之间有以下主要区别:

1. 连接方式:
   - TCP 是面向连接的协议,在数据传输前需要建立连接。
   - UDP 是无连接的协议,不需要建立连接就可以传输数据。

2. 可靠性:
   - TCP 提供可靠的数据传输,会进行数据包的重传和顺序控制。
   - UDP 不提供可靠性保证,数据包可能会丢失、乱序或重复。

3. 传输方式:
   - TCP 是面向**字节流**的,将数据看作一连串的无结构字节流。
   - UDP 是面向报文的,保留应用程序发送的报文边界。

4. 传输效率:
   - TCP 由于需要连**接建立、数据包重传等,**传输效率较低。
   - UDP 由于**无连接、无重传机制,**传输效率较高。

5. 应用场景:
   - TCP 适用于要求高可靠性的应用,如 **Web、FTP、Email等**。
   - UDP 适用于对实时性要求高、但可靠性要求不高的应用,如**视频会议、在线游戏等**。

总之,TCP 和 UDP 各有优缺点,适用于不同的应用场景。TCP 提供了可靠的数据传输,而 UDP 则更注重传输效率和实时性。在实际应用中,两种协议常常配合使用,充分发挥各自的优势。

# UDP怎么进行局域广播？

在 UDP 协议中,可以使用广播来实现局域网内的数据传输。UDP 广播的步骤如下:

1. 设置广播地址
   - 广播地址是一种特殊的 IP 地址,用于向局域网内所有主机发送数据。
   - 在 IPv4 网络中,广播地址通常是 `255.255.255.255`。
2. 创建 UDP 广播套接字
   - 在编程时,需要创建一个 UDP 套接字并将其绑定到一个本地 IP 地址。
3. 设置 Socket 选项
   - 需要设置 `SO_BROADCAST` 套接字选项,允许发送广播数据包。
4. 发送广播数据包
   - 使用 `sendto()` 函数发送数据包,将目的地址设置为广播地址。
   - 在 IPv4 网络中,目的地址为 `255.255.255.255`。
5. 接收广播数据包
   - 广播数据包会被局域网内所有主机接收。
   - 接收方可以使用 `recvfrom()` 函数读取广播数据包。

需要注意的是,广播数据包`只能在局域网内传输,`不会`跨越路由器`传输到其他`网段`。如果需要跨网段通信,可以考虑使用`组播(Multicast)机制`。

总之,UDP 广播为局域网内的数据传输提供了一种简单有效的方式,适用于一对多的通信场景,如服务发现、消息通知等。

# 什么是组播

组播(Multicast)是一种网络通信方式,它允许一个源向一个特定的组(Multicast Group)中的多个接收者同时发送数据。这与单播(Unicast,一对一)和广播(Broadcast,一对全体)有所不同。

组播的主要特点包括:

1. 一对多通信:
   - 组播可以实现一个发送者向多个接收者同时发送数据。
   - 这种通信方式比单播更有效率,因为发送者只需要发送一次数据即可。

2. 动态加入/退出:
   - 接收者可以动态地加入或退出组播组,接收来自组播源的数据。
   - 组播组成员是动态变化的,可以根据需要随时加入或退出。

3. 网络带宽优化:
   - 组播可以大幅减少网络带宽的消耗,因为数据只需在必要的网络链路上传输一次。
   - 这对于大规模的多媒体传输、视频会议等应用场景非常有利。

组播使用特殊的 IP 地址范围来标识组播组,IPv4 组播地址范围是 `224.0.0.0 ~ 239.255.255.255`，IPv6 组播地址以 `FF` 开头。

组播通信需要路由器和主机都支持组播路由协议,如IGMP(Internet Group Management Protocol)和MLD(Multicast Listener Discovery)。这些协议负责管理组播组成员,建立组播转发树等。

组播广泛应用于`视频直播、视频会议、实时数据传输等`场景,是实现高效网络通信的重要技术之一。

# mqtt协议基于什么？

MQTT协议基于发布/订阅模型。

# TCP重传的机制

TCP重传机制包括：

1. **超时重传**：当发送的数据段在一定时间内未收到确认（ACK），TCP会重传该数据段。
2. **快速重传**：当接收方**收到失序的段**，它会发送**重复确认**。发送方收到三个相同的确认后，会立即重传未收到的段，而不需要等待超时。
3. **选择性确认（SACK）**：允许接收方告知发送方哪些特定段已成功接收，**从而只重传丢失的段**。
4. **拥塞控制**：重传会触发拥塞控制算法，减少发送速率，避免加剧网络拥塞。

# 拥塞控制

拥塞控制是网络中用于防止数据包过多导致网络过载的机制，主要包括：

1. **流量控制**：限制发送速率，以匹配接收方处理能力。

2. **拥塞避免**：通过检测网络拥塞迹象，如重复ACK或丢包，来减少发送速率。

3. **拥塞检测**：使用算法（如**慢启动、拥塞避免、快速恢复**）来识别网络拥塞。

4. **丢包处理**：当检测到丢包时，采取措施减少发送速率，避免重传风暴。

5. **窗口缩放**：调整TCP窗口大小，以适应网络条件，避免拥塞。

   ![img](D:\A_Document\Routine_Document\实习\学习\v2-f7db63b1f00cbd8170e1435616e06216_720w.webp)

   ## 简述tcp识别并解决网络中拥塞问题的过程

    TCP识别并解决网络中拥塞问题的过程通常包括以下几个步骤：

   1. **慢启动**：开始时，TCP缓慢增加发送速率，指数级增长窗口大小。

   2. **拥塞避免**：达到一定阈值后，窗口大小增长变慢，线性增长。

   3. **丢包检测**：通过`定时器或连续的重复ACK（快速重传的触发）来检测丢包。`

   4. **丢包响应**：一旦`检测到丢包，通过减半窗口大小（拥塞窗口缩减）来减少发送速率。`

   5. **快速重传**：在收到三个重复的ACK时，立即重传丢失的段，而不是等待重传计时器超时。

   6. **快速恢复**：在减半窗口大小后，进入快速恢复阶段，逐步增加窗口大小，避免长时间的低速传输。

   7. **随机早期检测（RED）**：网络设备在缓冲区满之前`开始随机丢包`，以`提示发送方减少发送速率。`

   8. **显式拥塞通知（ECN）**：网络设备通过`IP数据包的ECN标记来通知发送方网络即将拥塞`。

   9. **适当缩放窗口**：根据`网络反馈，动态调整窗口大小，以匹配网络容量而避免拥塞`。

   通过这些机制，TCP能够在不牺牲公平性和避免过多丢包的前提下，动态地调整数据传输速率。

# TCP滑动窗口

[『面试问答』：TCP的流量控制是如何实现的？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ju4y1G7wB/?spm_id_from=333.788&vd_source=c4b26319211bc9ccc5ba3a0a22916e39)

![image-20240329145708788](D:\A_Document\Routine_Document\实习\学习\image-20240329145708788.png)

![image-20240329145853642](D:\A_Document\Routine_Document\实习\学习\image-20240329145853642.png)

![image-20240329145915596](D:\A_Document\Routine_Document\实习\学习\image-20240329145915596.png)



# s指针指向字符串变量，为什么不可以被改变。

在C语言中，当你使用指针指向一个字符串字面量（如 `char *s = "Hello";`），这个指针 `s` 指向的是一个存储在程序的`只读数据段`的字符串。这意味着字符串的内容是由程序在编译时确定的，并且在程序的整个运行过程中不可更改。试图通过这个指针修改字符串的内容将导致未定义行为，通常是程序崩溃。
这里有几个关键点需要注意：

1. **字符串字面量存储位置**：字符串字面量通常存储在只读的数据段中。

2. **指针的不可变性**：指针 `s` 自身的值（即指向的地址）在赋值后可以被改变，但是通过这个指针修改其指向的字符串内容是不允许的。

3. **字符串的不可变性**：由于字符串字面量存储在只读内存区域，因此它们的内容在程序执行期间是不可修改的。

4. **赋值与修改**：可以将另一个指针的值赋给 `s`，使其指向另一个字符串或内存地址。但是，通过 `s` 修改其初始指向的字符串字面量是不允许的。

如果你需要一个可修改的字符串，应该使用字符数组（例如 `char s[] = "Hello";`），这样字符串就被存储在可写的内存区域（通常是堆栈），并且其内容可以在程序中被修改。

例如：

```c
char s[] = "Hello"; // 正确，s是一个字符数组，内容可以修改
s[0] = 'h'; // 合法的修改，将字符串的第一个字符改为小写的 'h'

const char *t = "Hello"; // t 是一个指向字符串字面量的指针，指向的内容不可修改
t[0] = 'h'; // 错误，试图修改字符串字面量会导致未定义行为
```

在上述例子中，修改 `s` 是合法的，因为 `s` 是一个字符数组，其内容位于可写的内存区域。而对 `t` 的修改是不允许的，因为 `t` 指向一个字符串字面量，它位于只读的数据段。
